<!doctype html><html lang=en><head><meta charset=UTF-8><meta content="width=device-width,initial-scale=1.0" name=viewport><meta content="index, follow" name=robots><link href=https://noteoverflow.github.io/rss.xml rel=alternate title=RSS type=application/rss+xml><title>noteoverflow | Catamorphism as prototype of recursive algorithms</title><link as=style href=https://noteoverflow.github.io/css/style.css rel=preload><link crossorigin href=https://noteoverflow.github.io/css/reset-min.css rel=stylesheet><link crossorigin href=https://noteoverflow.github.io/css/suCSS-min.css rel=stylesheet><link href=https://noteoverflow.github.io/css/style.css rel=stylesheet><link href=https://noteoverflow.github.io/css/custom.css rel=stylesheet><link href=https://noteoverflow.github.io/img/favicon.ico rel=icon><body><nav id=nav-bar><a href=/> [post] </a><a href=/pinned> [pinned] </a><a href=/tags> [tag] </a><a href=/about> [about] </a>   <div aria-label="Toggle theme" class=theme-toggle data-icon-base=https://noteoverflow.github.io/icons.svg data-icon-dark=#darkMode data-icon-light=#lightMode data-sound-src=https://noteoverflow.github.io/click.ogg id=theme-toggle role=button tabindex=0><svg class=icon><use id=theme-icon></use></svg></div></nav><main><article class=post><header class=post-header><time datetime=2025-04-06>Published on: <span class=accent-data>2025-04-06</span> </time><h1>Catamorphism as prototype of recursive algorithms</h1></header><details><summary><i>Table of content</i></summary> <div class=toc-container><ul><li><a href=https://noteoverflow.github.io/posts/catamorphism-as-prototype-algo/#the-ultimate-principal>The ultimate principal</a><li><a href=https://noteoverflow.github.io/posts/catamorphism-as-prototype-algo/#tricks>Tricks</a> <ul><li><a href=https://noteoverflow.github.io/posts/catamorphism-as-prototype-algo/#recursion-as-loops>Recursion as loops</a><li><a href=https://noteoverflow.github.io/posts/catamorphism-as-prototype-algo/#not-only-input-but-also-output>Not only input, but also output!</a><li><a href=https://noteoverflow.github.io/posts/catamorphism-as-prototype-algo/#recursion-on-side-effect>Recursion on side effect</a><li><a href=https://noteoverflow.github.io/posts/catamorphism-as-prototype-algo/#divide-one-aspect-at-a-time-never-both>Divide one aspect at a time, never both</a><li><a href=https://noteoverflow.github.io/posts/catamorphism-as-prototype-algo/#defer-dividing>Defer dividing</a><li><a href=https://noteoverflow.github.io/posts/catamorphism-as-prototype-algo/#reuse-space>Reuse space</a><li><a href=https://noteoverflow.github.io/posts/catamorphism-as-prototype-algo/#caching>Caching</a><li><a href=https://noteoverflow.github.io/posts/catamorphism-as-prototype-algo/#pruning>Pruning</a></ul><li><a href=https://noteoverflow.github.io/posts/catamorphism-as-prototype-algo/#catamorphisms-and-recursion-schemes>Catamorphisms and recursion schemes</a> <ul><li><a href=https://noteoverflow.github.io/posts/catamorphism-as-prototype-algo/#f-algebra>F-algebra</a><li><a href=https://noteoverflow.github.io/posts/catamorphism-as-prototype-algo/#basic-cata>Basic cata</a></ul></ul></div></details><div class=post-content><p><em>WARNING: This is just a informal post on algorithms and most of ideas are only checked on leetcode problems.</em><p>Actually I was trying to find some universal methods for solutions on algorithm problems. However, since I only have time to practise on leetcode problems and don't have time to explore in a much broader range like ACM, I hereby only demonstrate my discoveries during solving about 500 problems on leetcode:<blockquote><p>For most basic algorithms, no need to master various kinds of tricks and data structures. All these problems can be solved with one simple principal.</blockquote><p>You may be suspective. But you can just think that currently, nearly all algorithms of branches and loops are basically equivalent to those of lambda calculus with recursions. Any traditional algorithm which can be finished in finite steps can also be expressed with lambda calculus and recursions. In a nutshell, lambda calculus is turing complete!<hr><h2 id=the-ultimate-principal>The ultimate principal</h2><p>Wait! Our mission should be positing a uniform principal of problem solving. Why bother wasting time on lambda calculus and recursions? Now let me show you the magic! It can be described informally as:<blockquote><p>All problems can be deconstructed by its <strong>input, output and side-effect</strong>. We can recursively divide the problem until we can solve it trivially. Finally, we merge all recursive solutions and get the global solution.</blockquote><p>Actually, there's nothing novel here. This principal is just trying to reintroduce one archaic motto:<blockquote><p>All algorithms can be constructed by <strong>divide and conquer</strong>.</blockquote><p>The only difference is that the archaic principal said nothing about what to divide. Although this principal is so simple that it's even hard to be seen as a discovery, to actually use it, it's much much hard and there exists so many pitfalls. Most pitfalls are basically that, most materials and people failed to follow the principal， let alone finding tricks of it. Here I only enumerate some of crux tricks (someday I may write a systemaic book on this).<h2 id=tricks>Tricks</h2><h3 id=recursion-as-loops>Recursion as loops</h3><p>All recursions can be converted to equivalent version of loops with extra data structure(such as <em>stack)</em>. In fact, all stack based compilers do this for you automatically.<ul><li><input disabled type=checkbox> show one perticular example</ul><h3 id=not-only-input-but-also-output>Not only input, but also output!</h3><p>One common misunderstanding is problems can only be divided by input. In practice, dividing output is quite useful and ubiquitous. Whenever you have difficulty dividing on input, just try output!<blockquote><p>All information (data) representing part of the problem can be divided. Although different dividing startegies can lead to different complexities.</blockquote><h3 id=recursion-on-side-effect>Recursion on side effect</h3><p>Many people insist that many problems can not be solve by <em>divide and conquer</em> as the dividing is not local and cannot be merged into the global solution. However, they all ignored some very critical aspect: the side-effect of functions (algorithms).<p>In theory, side-effect should be anything that can influence referential transparency. The most interesting fact is that, if you think carefully, effects can be classified into compile-time and run-time.<h4 id=run-time-effect-extra-information>Run-time effect: extra information</h4><p>For a problem, the result of our recursion is not simply returning a local solution in most scenarios. I find that we usually need additional recursive information. This is a bit abstract, so let me give you an example, using the sliding window that we often see:<p>Sliding windows are typically described by divide and conquer: for an input list, decompose it into a list consisting of the last element and all the previous elements. Assuming that I have obtained the solution of all the previous elements (except the last element) through recursion, then we will find that the solution of the first half alone is not enough to support us to get a new solution after incorporating the last element. So we can simply include an additional information, that is, assume that the recursion of the first half can return us an additional information, this additional information contains some information about the sequence adjacent to the last element (in fact, this sequence is what many people call a sliding window). Using this additional information, we find that we can easily update the global solution.<p>Of course, don't forget that this extra information is recursive. When you require the first half to recursively return the extra information, you must also be able to return the updated extra information (which can be compared to the sliding update of a sliding window). Similarly, if you want to get extra information you want from the upper layer, make sure you can then provide it to the next layer. Although the sliding window is used as an example here, the application scope of the extra information technique is actually much more than that. You will find that monotone stacks, double pointers, prefix sums, etc. are all just special cases of extra information recursion.<h4 id=compile-time-effect-constraints-and-proofs>Compile-time effect: constraints and proofs</h4><p>Compile-time effects are rare to mention but also ubiquitous! Besides decomposing on run-time data, you can even divide constraints (proofs)! If you are familiar with <em>dependent type theory</em>, then this is much natural.<h3 id=divide-one-aspect-at-a-time-never-both>Divide one aspect at a time, never both</h3><p>So you start trying to decompose any data that you think might be useful, but remember never to consider decomposition in multiple dimensions. Instead, decompose the first data (dimension) first, and then consider whether to decompose the second dimension. Otherwise, you will definitely fall into chaos. The most typical example is high-dimensional dynamic optimization. For this kind of problem, you must not rush to decompose it all at once, as you cannot eat hot tofu in a hurry.<h3 id=defer-dividing>Defer dividing</h3><p>Actually, most problems tagged <code>easy</code> and <code>medium</code> can be divided directly by its input and output. The real hard part is lying under the target to be divided. For instance, in designing the famous <em>quick sort</em>, one learns to rearrange the target array before dividing and recursion. the rearrange can effecttively efface the cost of merging after the recursion which is inevitable in <code>merge sort</code>. Moreover, many hard problems do not directly divide on input or output, nor the given effects. To solve them, one need to design and find a way to effectively construct a new data structure to be divided and recur.<h3 id=reuse-space>Reuse space</h3><p>When you try to design additional information again, you may find that the memory used to store the additional information can be reused. In this case, you must try to reuse this memory, which can usually greatly reduce space complexity.<h3 id=caching>Caching</h3><p>Don't be afraid of dynamic programming. Just list the recursive formula of recursive divide and conquer, and then use a hashMap to cache the results. If you find that there is no circular dependency in the recursion, then you don't even need a hash. A simple array plus the space reuse mentioned above can solve all dynamic programming.<h3 id=pruning>Pruning</h3><p>Subproblems can be pruned. Greedy algorithms and early termination with backtracking are both trivially applicable.<h2 id=catamorphisms-and-recursion-schemes>Catamorphisms and recursion schemes</h2><h3 id=f-algebra>F-algebra</h3><ul><li><input disabled type=checkbox> complete formal description after</ul><h3 id=basic-cata>Basic cata</h3><p><img alt=cata src=/img/blog/catamorphism/catamorphism.png><p>The dividing-and-conquer part can be described by <em>catamorphism</em>. However, in many situations, one need to find a effective target data structure to be divided first which is the real enigma. I shall do more studies on this part.</div><div class=post-tags><a class=tag href=/tags/programming>#programming </a><a class=tag href=/tags/algo>#algo </a><a class=tag href=/tags/math>#math </a><a class=tag href=/tags/category-theory>#category-theory </a></div></article></main><footer><hr><div id=footer-container><i><a href=/test>Q.E.D.</a></i></div><br></footer><script defer src=https://noteoverflow.github.io/js/script.js></script>